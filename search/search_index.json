{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro","text":"<p><code>any-guardrail</code> is a Python library providing a single interface to different guardrails.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Refer to the Quickstart for instructions on installation and usage.</p>"},{"location":"#guardrails","title":"Guardrails","text":"<p>Refer to Guardrails for the parameters for each guardrail.</p> <p>Refer to AnyGuardrail for how to use the <code>AnyGuardrail</code> object.</p>"},{"location":"#for-ai-systems","title":"For AI Systems","text":"<p>This documentation is available in two AI-friendly formats:</p> <ul> <li>llms.txt - A structured overview with curated links to key documentation sections</li> <li>llms-full.txt - Complete documentation content concatenated into a single file</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or newer</li> </ul>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>Install with <code>pip</code>:</p> <pre><code>pip install any-guardrail\n</code></pre>"},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":"<p><code>AnyGuardrail</code> provides a seamless interface for interacting with the guardrail models. It allows you to see a list of all the supported guardrails, and to instantiate each supported guardrails. Here is a full example:</p> <pre><code>from any_guardrail import AnyGuardrail, GuardrailName, GuardrailOutput\n\nguardrail = AnyGuardrail.create(GuardrailName.DEEPSET)\n\nresult: GuardrailOutput = guardrail.validate(\"All smiles from me!\")\n\nassert not result.unsafe\n</code></pre>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>Some of the models on HuggingFace require extra permissions to use. To do this, you'll need to create a HuggingFace profile and manually go through the permissions. Then, you'll need to download the HuggingFace Hub and login. One way to do this is:</p> <pre><code>pip install --upgrade huggingface_hub\n\nhf auth login\n</code></pre> <p>More information can be found here: HuggingFace Hub</p>"},{"location":"api/any_guardrail/","title":"AnyGuardrail","text":""},{"location":"api/any_guardrail/#anyguardrail","title":"AnyGuardrail","text":""},{"location":"api/any_guardrail/#any_guardrail.api.AnyGuardrail","title":"<code>any_guardrail.api.AnyGuardrail</code>","text":"<p>Factory class for creating guardrail instances.</p> Source code in <code>src/any_guardrail/api.py</code> <pre><code>class AnyGuardrail:\n    \"\"\"Factory class for creating guardrail instances.\"\"\"\n\n    @classmethod\n    def get_supported_guardrails(cls) -&gt; list[GuardrailName]:\n        \"\"\"List all supported guardrails.\"\"\"\n        return list(GuardrailName)\n\n    @classmethod\n    def get_supported_model(cls, guardrail_name: GuardrailName) -&gt; list[str]:\n        \"\"\"Get the model IDs supported by a specific guardrail.\"\"\"\n        guardrail_class = cls._get_guardrail_class(guardrail_name)\n        return guardrail_class.SUPPORTED_MODELS\n\n    @classmethod\n    def get_all_supported_models(cls) -&gt; dict[str, list[str]]:\n        \"\"\"Get all model IDs supported by all guardrails.\"\"\"\n        model_ids = {}\n        for guardrail_name in cls.get_supported_guardrails():\n            model_ids[guardrail_name.value] = cls.get_supported_model(guardrail_name)\n        return model_ids\n\n    @classmethod\n    def create(cls, guardrail_name: GuardrailName, **kwargs: Any) -&gt; Guardrail:\n        \"\"\"Create a guardrail instance.\n\n        Args:\n            guardrail_name: The name of the guardrail to use.\n            **kwargs: Additional keyword arguments to pass to the guardrail constructor.\n\n        Returns:\n            A guardrail instance.\n\n        \"\"\"\n        guardrail_class = cls._get_guardrail_class(guardrail_name)\n        return guardrail_class(**kwargs)\n\n    @classmethod\n    def _get_guardrail_class(cls, guardrail_name: GuardrailName) -&gt; type[Guardrail]:\n        guardrail_module_name = f\"{guardrail_name.value}\"\n        module_path = f\"any_guardrail.guardrails.{guardrail_module_name}\"\n\n        module = importlib.import_module(module_path)\n        parts = re.split(r\"[^A-Za-z0-9]+\", guardrail_module_name)\n        candidate_name = \"\".join(p.capitalize() for p in parts if p)\n        guardrail_class = getattr(module, candidate_name, None)\n        if inspect.isclass(guardrail_class) and issubclass(guardrail_class, Guardrail):\n            return guardrail_class\n        msg = f\"Could not resolve guardrail class for '{guardrail_module_name}' in {module.__name__}\"\n        raise ImportError(msg)\n</code></pre>"},{"location":"api/any_guardrail/#any_guardrail.api.AnyGuardrail.create","title":"<code>create(guardrail_name, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a guardrail instance.</p> <p>Parameters:</p> Name Type Description Default <code>guardrail_name</code> <code>GuardrailName</code> <p>The name of the guardrail to use.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the guardrail constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Guardrail</code> <p>A guardrail instance.</p> Source code in <code>src/any_guardrail/api.py</code> <pre><code>@classmethod\ndef create(cls, guardrail_name: GuardrailName, **kwargs: Any) -&gt; Guardrail:\n    \"\"\"Create a guardrail instance.\n\n    Args:\n        guardrail_name: The name of the guardrail to use.\n        **kwargs: Additional keyword arguments to pass to the guardrail constructor.\n\n    Returns:\n        A guardrail instance.\n\n    \"\"\"\n    guardrail_class = cls._get_guardrail_class(guardrail_name)\n    return guardrail_class(**kwargs)\n</code></pre>"},{"location":"api/any_guardrail/#any_guardrail.api.AnyGuardrail.get_all_supported_models","title":"<code>get_all_supported_models()</code>  <code>classmethod</code>","text":"<p>Get all model IDs supported by all guardrails.</p> Source code in <code>src/any_guardrail/api.py</code> <pre><code>@classmethod\ndef get_all_supported_models(cls) -&gt; dict[str, list[str]]:\n    \"\"\"Get all model IDs supported by all guardrails.\"\"\"\n    model_ids = {}\n    for guardrail_name in cls.get_supported_guardrails():\n        model_ids[guardrail_name.value] = cls.get_supported_model(guardrail_name)\n    return model_ids\n</code></pre>"},{"location":"api/any_guardrail/#any_guardrail.api.AnyGuardrail.get_supported_guardrails","title":"<code>get_supported_guardrails()</code>  <code>classmethod</code>","text":"<p>List all supported guardrails.</p> Source code in <code>src/any_guardrail/api.py</code> <pre><code>@classmethod\ndef get_supported_guardrails(cls) -&gt; list[GuardrailName]:\n    \"\"\"List all supported guardrails.\"\"\"\n    return list(GuardrailName)\n</code></pre>"},{"location":"api/any_guardrail/#any_guardrail.api.AnyGuardrail.get_supported_model","title":"<code>get_supported_model(guardrail_name)</code>  <code>classmethod</code>","text":"<p>Get the model IDs supported by a specific guardrail.</p> Source code in <code>src/any_guardrail/api.py</code> <pre><code>@classmethod\ndef get_supported_model(cls, guardrail_name: GuardrailName) -&gt; list[str]:\n    \"\"\"Get the model IDs supported by a specific guardrail.\"\"\"\n    guardrail_class = cls._get_guardrail_class(guardrail_name)\n    return guardrail_class.SUPPORTED_MODELS\n</code></pre>"},{"location":"api/guardrails/","title":"Index","text":""},{"location":"api/guardrails/#guardrails","title":"Guardrails","text":"<p>This section documents the available guardrails and their parameters. Select a guardrail to view its API details.</p>"},{"location":"api/guardrails/any_llm/","title":"AnyLLM","text":""},{"location":"api/guardrails/any_llm/#any_guardrail.guardrails.any_llm","title":"<code>any_guardrail.guardrails.any_llm</code>","text":""},{"location":"api/guardrails/any_llm/#any_guardrail.guardrails.any_llm.AnyLlm","title":"<code>AnyLlm</code>","text":"<p>               Bases: <code>Guardrail</code></p> <p>A guardrail using <code>any-llm</code>.</p> Source code in <code>src/any_guardrail/guardrails/any_llm/any_llm.py</code> <pre><code>class AnyLlm(Guardrail):\n    \"\"\"A guardrail using `any-llm`.\"\"\"\n\n    def validate(\n        self,\n        input_text: str,\n        policy: str,\n        model_id: str = DEFAULT_MODEL_ID,\n        system_prompt: str = DEFAULT_SYSTEM_PROMPT,\n        **kwargs: Any,\n    ) -&gt; GuardrailOutput:\n        \"\"\"Validate the `input_text` against the given `policy`.\n\n        Args:\n            input_text (str): The text to validate.\n            policy (str): The policy to validate against.\n            model_id (str, optional): The model ID to use.\n            system_prompt (str, optional): The system prompt to use.\n                Expected to have a `{policy}` placeholder.\n            **kwargs: Additional keyword arguments to pass to `any_llm.completion` function.\n\n        Returns:\n            GuardrailOutput: The output of the validation.\n\n        \"\"\"\n        result: ChatCompletion = completion(  # type: ignore[assignment]\n            model=model_id,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt.format(policy=policy)},\n                {\"role\": \"user\", \"content\": input_text},\n            ],\n            response_format=GuardrailOutput,\n            **kwargs,\n        )\n        return GuardrailOutput(**json.loads(result.choices[0].message.content))  # type: ignore[arg-type]\n</code></pre>"},{"location":"api/guardrails/any_llm/#any_guardrail.guardrails.any_llm.AnyLlm.validate","title":"<code>validate(input_text, policy, model_id=DEFAULT_MODEL_ID, system_prompt=DEFAULT_SYSTEM_PROMPT, **kwargs)</code>","text":"<p>Validate the <code>input_text</code> against the given <code>policy</code>.</p> <p>Parameters:</p> Name Type Description Default <code>input_text</code> <code>str</code> <p>The text to validate.</p> required <code>policy</code> <code>str</code> <p>The policy to validate against.</p> required <code>model_id</code> <code>str</code> <p>The model ID to use.</p> <code>DEFAULT_MODEL_ID</code> <code>system_prompt</code> <code>str</code> <p>The system prompt to use. Expected to have a <code>{policy}</code> placeholder.</p> <code>DEFAULT_SYSTEM_PROMPT</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to <code>any_llm.completion</code> function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>GuardrailOutput</code> <code>GuardrailOutput</code> <p>The output of the validation.</p> Source code in <code>src/any_guardrail/guardrails/any_llm/any_llm.py</code> <pre><code>def validate(\n    self,\n    input_text: str,\n    policy: str,\n    model_id: str = DEFAULT_MODEL_ID,\n    system_prompt: str = DEFAULT_SYSTEM_PROMPT,\n    **kwargs: Any,\n) -&gt; GuardrailOutput:\n    \"\"\"Validate the `input_text` against the given `policy`.\n\n    Args:\n        input_text (str): The text to validate.\n        policy (str): The policy to validate against.\n        model_id (str, optional): The model ID to use.\n        system_prompt (str, optional): The system prompt to use.\n            Expected to have a `{policy}` placeholder.\n        **kwargs: Additional keyword arguments to pass to `any_llm.completion` function.\n\n    Returns:\n        GuardrailOutput: The output of the validation.\n\n    \"\"\"\n    result: ChatCompletion = completion(  # type: ignore[assignment]\n        model=model_id,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt.format(policy=policy)},\n            {\"role\": \"user\", \"content\": input_text},\n        ],\n        response_format=GuardrailOutput,\n        **kwargs,\n    )\n    return GuardrailOutput(**json.loads(result.choices[0].message.content))  # type: ignore[arg-type]\n</code></pre>"},{"location":"api/guardrails/deepset/","title":"Deepset","text":""},{"location":"api/guardrails/deepset/#any_guardrail.guardrails.deepset","title":"<code>any_guardrail.guardrails.deepset</code>","text":""},{"location":"api/guardrails/deepset/#any_guardrail.guardrails.deepset.Deepset","title":"<code>Deepset</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Wrapper for prompt injection detection model from Deepset.</p> <p>For more information, please see the model card:</p> <ul> <li>Deepset.</li> </ul> Source code in <code>src/any_guardrail/guardrails/deepset/deepset.py</code> <pre><code>class Deepset(HuggingFace):\n    \"\"\"Wrapper for prompt injection detection model from Deepset.\n\n    For more information, please see the model card:\n\n    - [Deepset](https://huggingface.co/deepset/deberta-v3-base-injection).\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"deepset/deberta-v3-base-injection\"]\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        return _match_injection_label(model_outputs, DEEPSET_INJECTION_LABEL, self.model.config.id2label)\n</code></pre>"},{"location":"api/guardrails/duo_guard/","title":"Duo Guard","text":""},{"location":"api/guardrails/duo_guard/#any_guardrail.guardrails.duo_guard","title":"<code>any_guardrail.guardrails.duo_guard</code>","text":""},{"location":"api/guardrails/duo_guard/#any_guardrail.guardrails.duo_guard.DuoGuard","title":"<code>DuoGuard</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Guardrail that classifies text based on the categories in DUOGUARD_CATEGORIES.</p> <p>For more information, please see the model card:</p> <ul> <li>DuoGuard.</li> </ul> Source code in <code>src/any_guardrail/guardrails/duo_guard/duo_guard.py</code> <pre><code>class DuoGuard(HuggingFace):\n    \"\"\"Guardrail that classifies text based on the categories in DUOGUARD_CATEGORIES.\n\n    For more information, please see the model card:\n\n    - [DuoGuard](https://huggingface.co/collections/DuoGuard/duoguard-models-67a29ad8bd579a404e504d21).\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\n        \"DuoGuard/DuoGuard-0.5B\",\n        \"DuoGuard/DuoGuard-1B-Llama-3.2-transfer\",\n        \"DuoGuard/DuoGuard-1.5B-transfer\",\n    ]\n\n    MODELS_TO_TOKENIZER: ClassVar = {\n        \"DuoGuard/DuoGuard-0.5B\": \"Qwen/Qwen2.5-0.5B\",\n        \"DuoGuard/DuoGuard-1B-Llama-3.2-transfer\": \"meta-llama/Llama-3.2-1B\",\n        \"DuoGuard/DuoGuard-1.5B-transfer\": \"Qwen/Qwen2.5-1.5B\",\n    }\n\n    def __init__(self, model_id: str | None = None, threshold: float = DUOGUARD_DEFAULT_THRESHOLD) -&gt; None:\n        \"\"\"Initialize the DuoGuard model.\"\"\"\n        super().__init__(model_id)\n        self.threshold = threshold\n\n    def _load_model(self) -&gt; None:\n        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_id)\n        self.tokenizer = AutoTokenizer.from_pretrained(self.MODELS_TO_TOKENIZER[self.model_id])  # type: ignore[no-untyped-call]\n        self.tokenizer.pad_token = self.tokenizer.eos_token\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        probabilities = torch.sigmoid(model_outputs[\"logits\"][0]).tolist()\n        predicted_labels = {\n            category: prob &gt; self.threshold for category, prob in zip(DUOGUARD_CATEGORIES, probabilities, strict=True)\n        }\n        return GuardrailOutput(\n            unsafe=any(predicted_labels.values()), explanation=predicted_labels, score=max(probabilities)\n        )\n</code></pre>"},{"location":"api/guardrails/duo_guard/#any_guardrail.guardrails.duo_guard.DuoGuard.__init__","title":"<code>__init__(model_id=None, threshold=DUOGUARD_DEFAULT_THRESHOLD)</code>","text":"<p>Initialize the DuoGuard model.</p> Source code in <code>src/any_guardrail/guardrails/duo_guard/duo_guard.py</code> <pre><code>def __init__(self, model_id: str | None = None, threshold: float = DUOGUARD_DEFAULT_THRESHOLD) -&gt; None:\n    \"\"\"Initialize the DuoGuard model.\"\"\"\n    super().__init__(model_id)\n    self.threshold = threshold\n</code></pre>"},{"location":"api/guardrails/flowjudge/","title":"FlowJudge","text":""},{"location":"api/guardrails/flowjudge/#any_guardrail.guardrails.flowjudge","title":"<code>any_guardrail.guardrails.flowjudge</code>","text":""},{"location":"api/guardrails/flowjudge/#any_guardrail.guardrails.flowjudge.Flowjudge","title":"<code>Flowjudge</code>","text":"<p>               Bases: <code>Guardrail</code></p> <p>Wrapper around FlowJudge, allowing for custom guardrailing based on user defined criteria, metrics, and rubric.</p> <p>Please see the model card for more information: FlowJudge.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>User defined metric name.</p> required <code>criteria</code> <code>str</code> <p>User defined question that they want answered by FlowJudge model.</p> required <code>rubric</code> <code>dict[int, str]</code> <p>A scoring rubric in a likert scale fashion, providing an integer score and then a description of what the value means.</p> required <code>required_inputs</code> <code>list[str]</code> <p>A list of what is required for the judge to consider.</p> required <code>required_output</code> <code>str</code> <p>What is the expected output from the judge.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Only supports FlowJudge keywords to instantiate FlowJudge.</p> Source code in <code>src/any_guardrail/guardrails/flowjudge/flowjudge.py</code> <pre><code>class Flowjudge(Guardrail):\n    \"\"\"Wrapper around FlowJudge, allowing for custom guardrailing based on user defined criteria, metrics, and rubric.\n\n    Please see the model card for more information: [FlowJudge](https://huggingface.co/flowaicom/Flow-Judge-v0.1).\n\n    Args:\n        name: User defined metric name.\n        criteria: User defined question that they want answered by FlowJudge model.\n        rubric: A scoring rubric in a likert scale fashion, providing an integer score and then a description of what the\n            value means.\n        required_inputs: A list of what is required for the judge to consider.\n        required_output: What is the expected output from the judge.\n\n    Raises:\n        ValueError: Only supports FlowJudge keywords to instantiate FlowJudge.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        criteria: str,\n        rubric: dict[int, str],\n        required_inputs: list[str],\n        required_output: str,\n    ) -&gt; None:\n        \"\"\"Initialize the FlowJudgeClass.\"\"\"\n        self.metric_name = name\n        self.criteria = criteria\n        self.rubric = rubric\n        self.required_inputs = required_inputs\n        self.required_output = required_output\n        self.metric_prompt = self._define_metric_prompt()\n\n    def validate(self, inputs: list[dict[str, str]], output: dict[str, str]) -&gt; GuardrailOutput:\n        \"\"\"Classifies the desired input and output according to the associated metric provided to the judge.\n\n        Args:\n            inputs: A dictionary mapping the required input names to the inputs.\n            output: A dictionary mapping the required output name to the output.\n\n        Return:\n            A score from the RubricItems and feedback related to the rubric and criteria.\n\n        \"\"\"\n        eval_input = self._pre_processing(inputs, output)\n        result = self._inference(eval_input)\n        return GuardrailOutput(explanation=result.feedback, score=result.score)\n\n    def _load_model(self) -&gt; None:\n        \"\"\"Construct the FlowJudge model using the defined metric prompt that contains the rubric, criteria, and metric.\n\n        Returns:\n            judge: The evaluation model.\n\n        \"\"\"\n        model = Hf(flash_attention=False)\n        judge = FlowJudge(metric=self.metric_prompt, model=model)\n        self.model = judge\n\n    def _define_metric_prompt(self) -&gt; Metric:\n        \"\"\"Construct the Metric object needed to instantiate the FlowJudge model.\n\n        Returns:\n            The Metric object used to construct the FlowJudge model.\n\n        \"\"\"\n        processed_rubric = self._construct_rubric()\n        return Metric(\n            name=self.metric_name,\n            criteria=self.criteria,\n            rubric=processed_rubric,\n            required_inputs=self.required_inputs,\n            required_output=self.required_output,\n        )\n\n    def _construct_rubric(self) -&gt; list[RubricItem]:\n        \"\"\"Construct the rubric from a user defined rubric dicitionary to construct the Metric object.\n\n        Returns:\n            List of RubricItem objects.\n\n        \"\"\"\n        processed_rubric = []\n        for key, value in self.rubric.items():\n            rubric_item = RubricItem(score=key, description=value)\n            processed_rubric.append(rubric_item)\n        return processed_rubric\n\n    def _pre_processing(self, inputs: list[dict[str, str]], output: dict[str, str]) -&gt; EvalInput:\n        return EvalInput(inputs=inputs, output=output)\n\n    def _inference(self, eval_input: EvalInput) -&gt; EvalOutput:\n        return self.model.evaluate(eval_input, save_results=False)\n</code></pre>"},{"location":"api/guardrails/flowjudge/#any_guardrail.guardrails.flowjudge.Flowjudge.__init__","title":"<code>__init__(name, criteria, rubric, required_inputs, required_output)</code>","text":"<p>Initialize the FlowJudgeClass.</p> Source code in <code>src/any_guardrail/guardrails/flowjudge/flowjudge.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    criteria: str,\n    rubric: dict[int, str],\n    required_inputs: list[str],\n    required_output: str,\n) -&gt; None:\n    \"\"\"Initialize the FlowJudgeClass.\"\"\"\n    self.metric_name = name\n    self.criteria = criteria\n    self.rubric = rubric\n    self.required_inputs = required_inputs\n    self.required_output = required_output\n    self.metric_prompt = self._define_metric_prompt()\n</code></pre>"},{"location":"api/guardrails/flowjudge/#any_guardrail.guardrails.flowjudge.Flowjudge.validate","title":"<code>validate(inputs, output)</code>","text":"<p>Classifies the desired input and output according to the associated metric provided to the judge.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>list[dict[str, str]]</code> <p>A dictionary mapping the required input names to the inputs.</p> required <code>output</code> <code>dict[str, str]</code> <p>A dictionary mapping the required output name to the output.</p> required Return <p>A score from the RubricItems and feedback related to the rubric and criteria.</p> Source code in <code>src/any_guardrail/guardrails/flowjudge/flowjudge.py</code> <pre><code>def validate(self, inputs: list[dict[str, str]], output: dict[str, str]) -&gt; GuardrailOutput:\n    \"\"\"Classifies the desired input and output according to the associated metric provided to the judge.\n\n    Args:\n        inputs: A dictionary mapping the required input names to the inputs.\n        output: A dictionary mapping the required output name to the output.\n\n    Return:\n        A score from the RubricItems and feedback related to the rubric and criteria.\n\n    \"\"\"\n    eval_input = self._pre_processing(inputs, output)\n    result = self._inference(eval_input)\n    return GuardrailOutput(explanation=result.feedback, score=result.score)\n</code></pre>"},{"location":"api/guardrails/glider/","title":"Glider","text":""},{"location":"api/guardrails/glider/#any_guardrail.guardrails.glider","title":"<code>any_guardrail.guardrails.glider</code>","text":""},{"location":"api/guardrails/glider/#any_guardrail.guardrails.glider.Glider","title":"<code>Glider</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>A prompt based guardrail from Patronus AI that utilizes pass criteria and a rubric to judge text.</p> <p>For more information, see the model card:GLIDER. It outputs its reasoning, highlights for what determined the score, and an integer score.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>HuggingFace path to model.</p> required <code>pass_criteria</code> <code>str</code> <p>A question or description of what you are validating.</p> required <code>rubric</code> <code>str</code> <p>A scoring rubric, describing to the model how to score the provided data.</p> required Raise <p>ValueError: Can only use model path to GLIDER from HuggingFace.</p> Source code in <code>src/any_guardrail/guardrails/glider/glider.py</code> <pre><code>class Glider(HuggingFace):\n    \"\"\"A prompt based guardrail from Patronus AI that utilizes pass criteria and a rubric to judge text.\n\n    For more information, see the model card:[GLIDER](https://huggingface.co/PatronusAI/glider). It outputs its reasoning,\n    highlights for what determined the score, and an integer score.\n\n    Args:\n        model_id: HuggingFace path to model.\n        pass_criteria: A question or description of what you are validating.\n        rubric: A scoring rubric, describing to the model how to score the provided data.\n\n    Raise:\n        ValueError: Can only use model path to GLIDER from HuggingFace.\n\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"PatronusAI/glider\"]\n\n    def __init__(self, model_id: str, pass_criteria: str, rubric: str) -&gt; None:\n        \"\"\"Initialize the GLIDER guardrail.\"\"\"\n        super().__init__(model_id)\n        self.pass_criteria = pass_criteria\n        self.rubric = rubric\n        self.system_prompt = SYSTEM_PROMPT_GLIDER\n\n    def validate(self, input_text: str, output_text: str) -&gt; GuardrailOutput:  # type: ignore[override]\n        \"\"\"Use the provided pass criteria and rubric to judge the input and output text provided.\n\n        Args:\n            input_text: the initial text.\n            output_text: the subsequent text.\n\n        Returns:\n            An explanation in the format provided by the system prompt.\n\n        \"\"\"\n        message = self._pre_processing(input_text, output_text)\n        result = self._inference(message)\n        return GuardrailOutput(explanation=result)\n\n    def _load_model(self) -&gt; None:\n        pipe = pipeline(\"text-classification\", self.model_id)\n        self.model = pipe\n\n    def _pre_processing(self, input_text: str, output_text: str) -&gt; list[dict[str, str]]:  # type: ignore[override]\n        data = DEFAULT_DATA_FORMAT.format(input_text=input_text, output_text=output_text)\n        prompt = self.system_prompt.format(data=data, pass_criteria=self.pass_criteria, rubric=self.rubric)\n        return [{\"role\": \"user\", \"content\": prompt}]\n\n    def _inference(self, message: list[dict[str, str]]) -&gt; Any:\n        return self.model(message)[0][\"generated_text\"]\n</code></pre>"},{"location":"api/guardrails/glider/#any_guardrail.guardrails.glider.Glider.__init__","title":"<code>__init__(model_id, pass_criteria, rubric)</code>","text":"<p>Initialize the GLIDER guardrail.</p> Source code in <code>src/any_guardrail/guardrails/glider/glider.py</code> <pre><code>def __init__(self, model_id: str, pass_criteria: str, rubric: str) -&gt; None:\n    \"\"\"Initialize the GLIDER guardrail.\"\"\"\n    super().__init__(model_id)\n    self.pass_criteria = pass_criteria\n    self.rubric = rubric\n    self.system_prompt = SYSTEM_PROMPT_GLIDER\n</code></pre>"},{"location":"api/guardrails/glider/#any_guardrail.guardrails.glider.Glider.validate","title":"<code>validate(input_text, output_text)</code>","text":"<p>Use the provided pass criteria and rubric to judge the input and output text provided.</p> <p>Parameters:</p> Name Type Description Default <code>input_text</code> <code>str</code> <p>the initial text.</p> required <code>output_text</code> <code>str</code> <p>the subsequent text.</p> required <p>Returns:</p> Type Description <code>GuardrailOutput</code> <p>An explanation in the format provided by the system prompt.</p> Source code in <code>src/any_guardrail/guardrails/glider/glider.py</code> <pre><code>def validate(self, input_text: str, output_text: str) -&gt; GuardrailOutput:  # type: ignore[override]\n    \"\"\"Use the provided pass criteria and rubric to judge the input and output text provided.\n\n    Args:\n        input_text: the initial text.\n        output_text: the subsequent text.\n\n    Returns:\n        An explanation in the format provided by the system prompt.\n\n    \"\"\"\n    message = self._pre_processing(input_text, output_text)\n    result = self._inference(message)\n    return GuardrailOutput(explanation=result)\n</code></pre>"},{"location":"api/guardrails/harm_guard/","title":"Harm Guard","text":""},{"location":"api/guardrails/harm_guard/#any_guardrail.guardrails.harm_guard","title":"<code>any_guardrail.guardrails.harm_guard</code>","text":""},{"location":"api/guardrails/harm_guard/#any_guardrail.guardrails.harm_guard.HarmGuard","title":"<code>HarmGuard</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Prompt injection detection encoder based model.</p> <p>For more information, please see the model card:</p> <ul> <li>HarmGuard.</li> </ul> Source code in <code>src/any_guardrail/guardrails/harm_guard/harm_guard.py</code> <pre><code>class HarmGuard(HuggingFace):\n    \"\"\"Prompt injection detection encoder based model.\n\n    For more information, please see the model card:\n\n    - [HarmGuard](https://huggingface.co/hbseong/HarmAug-Guard).\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"hbseong/HarmAug-Guard\"]\n\n    def __init__(self, model_id: str | None = None, threshold: float = HARMGUARD_DEFAULT_THRESHOLD) -&gt; None:\n        \"\"\"Initialize the HarmGuard guardrail.\"\"\"\n        super().__init__(model_id)\n        self.threshold = threshold\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        logits = model_outputs[\"logits\"][0].numpy()\n        scores = _softmax(logits)  # type: ignore[no-untyped-call]\n        final_score = float(scores[1])\n        return GuardrailOutput(unsafe=final_score &gt; self.threshold, score=final_score)\n</code></pre>"},{"location":"api/guardrails/harm_guard/#any_guardrail.guardrails.harm_guard.HarmGuard.__init__","title":"<code>__init__(model_id=None, threshold=HARMGUARD_DEFAULT_THRESHOLD)</code>","text":"<p>Initialize the HarmGuard guardrail.</p> Source code in <code>src/any_guardrail/guardrails/harm_guard/harm_guard.py</code> <pre><code>def __init__(self, model_id: str | None = None, threshold: float = HARMGUARD_DEFAULT_THRESHOLD) -&gt; None:\n    \"\"\"Initialize the HarmGuard guardrail.\"\"\"\n    super().__init__(model_id)\n    self.threshold = threshold\n</code></pre>"},{"location":"api/guardrails/injec_guard/","title":"InjecGuard","text":""},{"location":"api/guardrails/injec_guard/#any_guardrail.guardrails.injec_guard","title":"<code>any_guardrail.guardrails.injec_guard</code>","text":""},{"location":"api/guardrails/injec_guard/#any_guardrail.guardrails.injec_guard.InjecGuard","title":"<code>InjecGuard</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Prompt injection detection encoder based model.</p> <p>For more information, please see the model card:</p> <ul> <li>InjecGuard.</li> </ul> Source code in <code>src/any_guardrail/guardrails/injec_guard/injec_guard.py</code> <pre><code>class InjecGuard(HuggingFace):\n    \"\"\"Prompt injection detection encoder based model.\n\n    For more information, please see the model card:\n\n    - [InjecGuard](https://huggingface.co/leolee99/InjecGuard).\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"leolee99/InjecGuard\"]\n\n    def _load_model(self) -&gt; None:\n        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_id, trust_remote_code=True)\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)  # type: ignore[no-untyped-call]\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        return _match_injection_label(model_outputs, INJECGUARD_LABEL, self.model.config.id2label)\n</code></pre>"},{"location":"api/guardrails/jasper/","title":"Jasper","text":""},{"location":"api/guardrails/jasper/#any_guardrail.guardrails.jasper","title":"<code>any_guardrail.guardrails.jasper</code>","text":""},{"location":"api/guardrails/jasper/#any_guardrail.guardrails.jasper.Jasper","title":"<code>Jasper</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Prompt injection detection encoder based models.</p> <p>For more information, please see the model card:</p> <ul> <li>Jasper Deberta</li> <li>Jasper Gelectra.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str | None</code> <p>HuggingFace path to model.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Can only use model paths for Jasper models from HuggingFace.</p> Source code in <code>src/any_guardrail/guardrails/jasper/jasper.py</code> <pre><code>class Jasper(HuggingFace):\n    \"\"\"Prompt injection detection encoder based models.\n\n    For more information, please see the model card:\n\n    - [Jasper Deberta](https://huggingface.co/JasperLS/deberta-v3-base-injection)\n    - [Jasper Gelectra](https://huggingface.co/JasperLS/gelectra-base-injection).\n\n    Args:\n        model_id: HuggingFace path to model.\n\n    Raises:\n        ValueError: Can only use model paths for Jasper models from HuggingFace.\n\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"JasperLS/gelectra-base-injection\", \"JasperLS/deberta-v3-base-injection\"]\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        return _match_injection_label(model_outputs, JASPER_INJECTION_LABEL, self.model.config.id2label)\n</code></pre>"},{"location":"api/guardrails/pangolin/","title":"Pangolin","text":""},{"location":"api/guardrails/pangolin/#any_guardrail.guardrails.pangolin","title":"<code>any_guardrail.guardrails.pangolin</code>","text":""},{"location":"api/guardrails/pangolin/#any_guardrail.guardrails.pangolin.Pangolin","title":"<code>Pangolin</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Prompt injection detection encoder based models.</p> <p>For more information, please see the model card:</p> <ul> <li>Pangolin Base</li> </ul> Source code in <code>src/any_guardrail/guardrails/pangolin/pangolin.py</code> <pre><code>class Pangolin(HuggingFace):\n    \"\"\"Prompt injection detection encoder based models.\n\n    For more information, please see the model card:\n\n    - [Pangolin Base](https://huggingface.co/dcarpintero/pangolin-guard-base)\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"dcarpintero/pangolin-guard-base\"]\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        return _match_injection_label(model_outputs, PANGOLIN_INJECTION_LABEL, self.model.config.id2label)\n</code></pre>"},{"location":"api/guardrails/protectai/","title":"ProtectAI","text":""},{"location":"api/guardrails/protectai/#any_guardrail.guardrails.protectai","title":"<code>any_guardrail.guardrails.protectai</code>","text":""},{"location":"api/guardrails/protectai/#any_guardrail.guardrails.protectai.Protectai","title":"<code>Protectai</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Prompt injection detection encoder based models.</p> <p>For more information, please see the model card:</p> <ul> <li>ProtectAI.</li> </ul> Source code in <code>src/any_guardrail/guardrails/protectai/protectai.py</code> <pre><code>class Protectai(HuggingFace):\n    \"\"\"Prompt injection detection encoder based models.\n\n    For more information, please see the model card:\n\n    - [ProtectAI](https://huggingface.co/collections/protectai/llm-security-65c1f17a11c4251eeab53f40).\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\n        \"ProtectAI/deberta-v3-small-prompt-injection-v2\",\n        \"ProtectAI/distilroberta-base-rejection-v1\",\n        \"ProtectAI/deberta-v3-base-prompt-injection\",\n        \"ProtectAI/deberta-v3-base-prompt-injection-v2\",\n    ]\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        return _match_injection_label(model_outputs, PROTECTAI_INJECTION_LABEL, self.model.config.id2label)\n</code></pre>"},{"location":"api/guardrails/sentinel/","title":"Sentinel","text":""},{"location":"api/guardrails/sentinel/#any_guardrail.guardrails.sentinel","title":"<code>any_guardrail.guardrails.sentinel</code>","text":""},{"location":"api/guardrails/sentinel/#any_guardrail.guardrails.sentinel.Sentinel","title":"<code>Sentinel</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Prompt injection detection encoder based model.</p> <p>For more information, please see the model card:</p> <ul> <li>Sentinel.</li> </ul> Source code in <code>src/any_guardrail/guardrails/sentinel/sentinel.py</code> <pre><code>class Sentinel(HuggingFace):\n    \"\"\"Prompt injection detection encoder based model.\n\n    For more information, please see the model card:\n\n    - [Sentinel](https://huggingface.co/qualifire/prompt-injection-sentinel).\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\"qualifire/prompt-injection-sentinel\"]\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        return _match_injection_label(model_outputs, SENTINEL_INJECTION_LABEL, self.model.config.id2label)\n</code></pre>"},{"location":"api/guardrails/shield_gemma/","title":"Shield Gemma","text":""},{"location":"api/guardrails/shield_gemma/#any_guardrail.guardrails.shield_gemma","title":"<code>any_guardrail.guardrails.shield_gemma</code>","text":""},{"location":"api/guardrails/shield_gemma/#any_guardrail.guardrails.shield_gemma.ShieldGemma","title":"<code>ShieldGemma</code>","text":"<p>               Bases: <code>HuggingFace</code></p> <p>Wrapper class for Google ShieldGemma models.</p> <p>For more information, please visit the model cards: Shield Gemma.</p> <p>Note we do not support the image classifier.</p> Source code in <code>src/any_guardrail/guardrails/shield_gemma/shield_gemma.py</code> <pre><code>class ShieldGemma(HuggingFace):\n    \"\"\"Wrapper class for Google ShieldGemma models.\n\n    For more information, please visit the model cards: [Shield Gemma](https://huggingface.co/collections/google/shieldgemma-67d130ef8da6af884072a789).\n\n    Note we do not support the image classifier.\n    \"\"\"\n\n    SUPPORTED_MODELS: ClassVar = [\n        \"google/shieldgemma-2b\",\n        \"google/shieldgemma-9b\",\n        \"google/shieldgemma-27b\",\n        \"hf-internal-testing/tiny-random-Gemma3ForCausalLM\",\n    ]\n\n    def __init__(self, policy: str, threshold: float = DEFAULT_THRESHOLD, model_id: str | None = None) -&gt; None:\n        \"\"\"Initialize the ShieldGemma guardrail.\"\"\"\n        super().__init__(model_id)\n        self.policy = policy\n        self.system_prompt = SYSTEM_PROMPT_SHIELD_GEMMA\n        self.threshold = threshold\n\n    def _load_model(self) -&gt; None:\n        self.model = AutoModelForCausalLM.from_pretrained(self.model_id)\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)  # type: ignore[no-untyped-call]\n\n    def _pre_processing(self, input_text: str) -&gt; Any:\n        formatted_prompt = self.system_prompt.format(user_prompt=input_text, safety_policy=self.policy)\n        return super()._pre_processing(formatted_prompt)\n\n    def _post_processing(self, model_outputs: dict[str, Any]) -&gt; GuardrailOutput:\n        logits = model_outputs[\"logits\"]\n        vocab = self.tokenizer.get_vocab()\n        selected_logits = logits[0, -1, [vocab[\"Yes\"], vocab[\"No\"]]]\n        probabilities = softmax(selected_logits, dim=0)\n        score = probabilities[0].item()\n        return GuardrailOutput(unsafe=score &gt; self.threshold, explanation=None, score=score)\n</code></pre>"},{"location":"api/guardrails/shield_gemma/#any_guardrail.guardrails.shield_gemma.ShieldGemma.__init__","title":"<code>__init__(policy, threshold=DEFAULT_THRESHOLD, model_id=None)</code>","text":"<p>Initialize the ShieldGemma guardrail.</p> Source code in <code>src/any_guardrail/guardrails/shield_gemma/shield_gemma.py</code> <pre><code>def __init__(self, policy: str, threshold: float = DEFAULT_THRESHOLD, model_id: str | None = None) -&gt; None:\n    \"\"\"Initialize the ShieldGemma guardrail.\"\"\"\n    super().__init__(model_id)\n    self.policy = policy\n    self.system_prompt = SYSTEM_PROMPT_SHIELD_GEMMA\n    self.threshold = threshold\n</code></pre>"}]}